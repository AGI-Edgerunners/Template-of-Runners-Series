
<style>
    *,
*::before,
*::after {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font: normal 16px/1.5 "Helvetica Neue", sans-serif;
  background: #456990;
  color: #fff;
  overflow-x: hidden;
  padding-bottom: 50px;
}


/* INTRO SECTION
–––––––––––––––––––––––––––––––––––––––––––––––––– */

.intro {
  background: #F45B69;
  padding: 100px 0;
}

.container {
  width: 90%;
  max-width: 1200px;
  margin: 0 auto;
  text-align: center;
}

h1 {
  font-size: 2.5rem;
}


/* TIMELINE
–––––––––––––––––––––––––––––––––––––––––––––––––– */
.timeline ul li {
  list-style-type: none;
  position: relative;
  width: 6px;
  margin: 0 auto;
  padding-top: 50px;
  background: #fff;
}

.timeline ul li::after {
  content: '';
  position: absolute;
  left: 50%;
  bottom: 0;
  transform: translateX(-50%);
  width: 30px;
  height: 30px;
  border-radius: 50%;
  background: inherit;
}

.timeline ul li div {
  position: relative;
  bottom: 0;
  width: 400px;
  padding: 15px;
  background: #F45B69;
}

.timeline ul li div::before {
  content: '';
  position: absolute;
  bottom: 7px;
  width: 0;
  height: 0;
  border-style: solid;
}

.timeline ul li:nth-child(odd) div {
  left: 45px;
}

.timeline ul li:nth-child(odd) div::before {
  left: -15px;
  border-width: 8px 16px 8px 0;
  border-color: transparent #F45B69 transparent transparent;
}

.timeline ul li:nth-child(even) div {
  left: -439px;
}

.timeline ul li:nth-child(even) div::before {
  right: -15px;
  border-width: 8px 0 8px 16px;
  border-color: transparent transparent transparent #F45B69;
}
    </style>




<section class="intro">
  <div class="container">
    <h1>Runners-On-Non-Autoregressive</h1>
    This repo show a time line of papers in area Non-Autoregressive
  </div>
</section>



<section class="timeline">
  <ul>
  <li><div><time>[2023]</time> Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation | <a href="https://openreview.net/forum?id=LSz-gQyd0zE">[paper]</a> | [code]</div></li>
<li><div><time>[2023]</time> NarrowBERT: Accelerating Masked Language Model Pretraining and Inference | <a href="https://arxiv.org/abs/2301.04761">[paper]</a> | [code]</div></li>
<li><div><time>[2022]</time> DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models | <a href="https://arxiv.org/abs/2211.15029">[paper]</a> | <a href="https://github.com/Hzfinfdu/Diffusion-BERT">[code]</a></div></li>
<li><div><time>[2022]</time> GENIE: Large Scale Pre-training for Text Generation with Diffusion Model | <a href="https://www.researchgate.net/publication/366527397_GENIE_Large_Scale_Pre-training_for_Text_Generation_with_Diffusion_Model">[paper]</a> | [code]</div></li>
<li><div><time>[2021]</time> Non-Autoregressive Text Generation with Pre-trained Language Models | <a href="https://arxiv.org/abs/2102.08220">[paper]</a> | <a href="https://github.com/yxuansu/NAG-BERT">[code]</a></div></li>
  </ul>
</section>


